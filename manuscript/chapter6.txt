-# 6. Data Modeling With JOIN

Join is a joy to work with in my opinion. It makes data model easier to design. 
Without joy, we have to either embed or joinging
data with our code instead of database taking care of that for us. With embedding
document, we will hit a limit point about document size because the document 
will usually loaded into the memory. Embedding document has its own advantages
such as: query data is simple, but this section will focus on data modeling with
*JOIN*.

# Using Join

## eqJoin

In RethinkDB, **JOIN** is automatically distributed, meaning if you run on a cluster, the data
will be combined from many clusters and presents final result to you.

In SQL, ideally you can join whatever you want by making sure that the records on 2
tables match a condition. An example:


    SELECT post.*
      FROM post
      JOIN comment ON comment.post_id=post.id

    # OR

    SELECT post.*
      FROM post
      JOIN comment ON comment.author_id=post.author_id

You don't even need to care about the index. The database is usually smart enough to figure out what index to use, or will scan the full table for you.

Join is a bit different in RethinkDB. Similar to how we have primary index and
second index, we usually need index to join in Rethink DB.

* primary keys
* secondary indexes
* sub queries

Let's explore why we need joins. Starting with one-to-many relationship. Let's find all compound and its synonyms. `eq_join` is used to join data:

    sequence.eqJoin(leftField, rightTable[, {index:'id'}]) → sequence
    sequence.eqJoin(function, rightTable[, {index:'id'}]) → sequence

It tries to find the document on table **righTable** whose index value matches leftField value or the return value of function. It's similar to `INNER JOIN` in MySQL.

    r.db("foodb")
      .table("compound_synonyms")
      .eqJoin("compound_id", r.db("foodb").table("compounds"))

And we get this:

    r.db("foodb")
      .table("compound_synonyms")
      .eqJoin("compound_id", r.db("foodb").table("compounds"))
    #=>
      "left": {
          "compound_id": 82 ,
          "created_at": Fri Apr 09 2010 17:40:05 GMT-07:00 ,
          "id": 832 ,
          "source":  "db_source" ,
          "synonym":  "3,4,2',4'-Tetrahydroxychalcone" ,
          "updated_at": Fri Apr 09 2010 17:40:05 GMT-07:00
          } ,
          "right": {
          "annotation_quality":  "low" ,
          "assigned_to_id": null ,
          "bigg_id": null ,
          "boiling_point": null ,
          "boiling_point_reference": null ,
          "cas_number": null ,
          "charge": null ,
          "charge_reference": null ,
          "chebi_id": null ,
          "comments": null ,
          "compound_source":  "PHENOLEXPLORER" ,
          "created_at": Thu Apr 08 2010 22:04:26 GMT-07:00 ,
          "creator_id": null ,
          "density": null ,
          "density_reference": null ,
          "description": null ,
          "dfc_id": null ,
          "dfc_name": null ,
          "drugbank_id": null ,
          "duke_id":  "BUTEIN" ,
          "duplicate_id": null ,
          "eafus_id": null ,
          "experimental_logp": null ,
          "experimental_logp_reference": null ,
          "experimental_pka": null ,
          "experimental_pka_reference": null ,
          "experimental_solubility": null ,
          "experimental_solubility_reference": null ,
          "export": false ,
          "flavornet_id": null ,
          "genbank_id": null ,
          "general_citations": null ,
          "goodscent_id": null ,
          "het_id": null ,
          "hmdb_id": null ,
          "hydrophobicity": null ,
          "hydrophobicity_reference": null ,
          "id": 82 ,
          "isoelectric_point": null ,
          "isoelectric_point_reference": null ,
          "kegg_compound_id":  "C08578" ,
          "knapsack_id":  "C00006941" ,
          "legacy_id": 99 ,
          "mass_spec_content_type": null ,
          "mass_spec_file_name": null ,
          "mass_spec_file_size": null ,
          "mass_spec_updated_at": null ,
          "melting_point": null ,
          "melting_point_reference": null ,
          "metabolism": null ,
          "moldb_alogps_logp":  "2.61" ,
          "moldb_alogps_logs":  "-3.57" ,
          "moldb_alogps_solubility":  "7.38e-02 g/l" ,
          "moldb_average_mass":  "272.2528" ,
          "moldb_formula":  "C15H12O5" ,
          "moldb_id": 41513 ,
          "moldb_inchi": "InChI=1S/C15H12O5/c16-10-3-4-11(14(19)8-10)12(17)5-1-9-2-6-13(18)15(20)7-9/h1-8,16,18-20H/b5-1+" ,
          "moldb_inchikey":  "InChIKey=AYMYWHCQALZEGT-ORCRQEGFSA-N" ,
          "moldb_iupac":  "(2E)-1-(2,4-dihydroxyphenyl)-3-(3,4-dihydroxyphenyl)prop-2-en-1-one" ,
          "moldb_logp":  "3.33" ,
          "moldb_mono_mass":  "272.068473494" ,
          "moldb_pka":  "8.77" ,
          "moldb_smiles":  "OC1=CC=C(C(=O)\C=C\C2=CC(O)=C(O)C=C2)C(O)=C1" ,
          "msds_content_type": null ,
          "msds_file_name": null ,
          "msds_file_size": null ,
          "msds_updated_at": null ,
          "name":  "Butein" ,
          "old_dfc_id": null ,
          "optical_rotation": null ,
          "optical_rotation_reference": null ,
          "percent_composition": null ,
          "percent_composition_reference": null ,
          "phenolexplorer_id": 104 ,
          "phenolexplorer_metabolite_id": 104 ,
          "physical_description": null ,
          "physical_description_reference": null ,
          "protein_formula": null ,
          "protein_structure_content_type": null ,
          "protein_structure_file_name": null ,
          "protein_structure_file_size": null ,
          "protein_structure_updated_at": null ,
          "protein_weight": null ,
          "pubchem_compound_id":  "5281222" ,
          "pubchem_substance_id": null ,
          "public_id":  "FDB000082" ,
          "refractive_index": null ,
          "refractive_index_reference": null ,
          "state": null ,
          "structure_source":  "BIOSPIDER" ,
          "superscent_id": null ,
          "synthesis_citations": null ,
          "type":  "SmallMoleculeCompound" ,
          "uniprot_id": null ,
          "uniprot_name": null ,
          "updated_at": Fri Jan 20 2012 00:50:49 GMT-08:00 ,
          "updater_id": 2 ,
          "uv_index": null ,
          "uv_index_reference": null ,
          "wikipedia_id": null
          }
          }

We get back an array, with element on both table match our condition. We can see that the item on the left has its `compound_id` matchs `id` field of the one on the right. However, the above result with left, right is not very useful. It will be more useful if we can merge both side into a single document. To do that, we use `zip`

    r.db("foodb")
      .table("compound_synonyms")
      .eqJoin("compound_id", r.db("foodb").table("compounds"))
      .zip()
    //=>
    {
    "annotation_quality":  "low" ,
    "assigned_to_id": null ,
    "bigg_id": null ,
    "boiling_point":  "Bp14 72°" ,
    "boiling_point_reference":  "DFC" ,
    "cas_number":  "15707-34-3" ,
    "charge": null ,
    "charge_reference": null ,
    "chebi_id": null ,
    "comments": null ,
    "compound_id": 923 ,
    //...lot of other fields
    },
    //other document here as well

What `zip` does is that it merges right document into left document and returns that document, instead of a document
with two **left** and **right** field.

`zip` is not really flexible because it simply merges all the field. We can use some **transform** function
to transform the document into a more read-able document since we only care about `name` and its `synonym`:

    r.db("foodb")
      .table("compound_synonyms")
      .eqJoin(
        "compound_id", 
        r.db("foodb").table("compounds")
      )
      .map(function (doc) {
        return {synonym: doc("left")("synonym"), name: doc("right")("name")}
      })
    //=>
    {
      "name":  "Butein" ,
      "synonym":  "Acrylophenone, 2',4'-dihydroxy-3-(3,4-dihydroxyphenyl)-"
    },
    {
      "name":  "3,4-Dimethoxybenzoic acid" ,
      "synonym":  "Benzoic acid, 3,4-dimethoxy-"
    }

Much cleaner now! The important thing is that the join data is just another stream or array 
and we can do transformation on it.

As you may see, we don't need to specify an index on above query. When we don't
specify index, RethinkDB use primary key of table. In this case, the primary key
is `id` field of `compounds`. Now loking at the query, it seems a bit awkard 
because `compound_synonyms` comes first. We can make it more natural, just follow above
syntax: for each document on `compounds`, fetch all document on
`compound_synonyms` where document's `compound_id` field match id of document
on `compounds` table. So now we see that we have to have an index on 
`compound_synonyms` table for `compound_id` field. Let's create an index for it:

        r.db("foodb").table("compounds")
          .indexCreate("compound_id")

Note that we can always query index status by using `indexStatus`

        r.db("foodb").table("compound_synonyms").indexStatus()

Until we get status ready(this table is really big btw):

        [
        {
        "function": <binary, 185 bytes, "24 72 65 71 6c 5f..."> ,
        "geo": false ,
        "index":  "compound_id" ,
        "multi": false ,
        "outdated": false ,
        "ready": true
        }
        ]

Let's try it out:

    r.db("foodb")
      .table("compounds")
      .eqJoin("id", r.db("foodb").table("compound_synonyms"), {index: 'compound_id'})
      .map(function (doc) {
        return {synonym: doc("right")("synonym"), name: doc("left")("name")}
      })
    //=>
    {
    "name":  "Butein" ,
    "synonym":  "3-(3,4-Dihydroxy-phenyl)-1-(2,4-dihydroxy-phenyl)-propenone"
    } {
    "name":  "Butein" ,
    "synonym":  "2',3,4,4'-Tetrahydroxychalcone"
    }

With proper index, a query may looks cleaner and more natural.
The order of how we use `eqJoin` is important. You should always try to narrow
down data first, so that the join do less works.

Also, we don't have `left join`, `right join` equivalents in RethinkDB. We achieve
it by swapping left and right on eqJoin with approriate index. So far, we only
join on a single field. How do we join in multile field condtion? Such as in
MySQL we can do

    SELECT * 
      FROM table1 as t1
    LEFT JOIN tabl2 as t2 ON t1.field1= t2.field1 AND 

How about complex join where we want either or ? Like in MySQL

    SELECT * 
      FROM table1 as t1
    LEFT JOIN tabl2 as t2 ON t1.field1= t2.field1  OR 

@TODO

To join, we usually need index. But can we join data without using any index
via two arbitray sequence? Even if it's not very efficient but useful to have.
The answer is yes, we can do inner join and outer join.

## innerJoin

innerJoin returns an inter section of two sequences where as each row of first
sequence will be put together with each row of second sequence then evaluate
a predicate function to find pair of row which predicate function returns true.
The syntax of `innerJoin` is:

    sequence.innerJoin(otherSequence, predicate) → stream
    array.innerJoin(otherSequence, predicate) → array

Predicate function accepts two parameters of each row of first and second
sequence.

Let's say the first sequence has `m` rows, and second sequence has `n` rows,
the innerJoin will loop ***M x N*** times and pass the pair of rows into
predicate function. Let's say we have two sequences:

    [2,5,8,12,15,20,21,24,25]
    [2,3,4]

And we want to find all pair of data where the first element module and second
element equal zero.

We can write this:

    r.expr([2,5,8,12,15,20,21,24,25])
      .innerJoin(
        r.expr([2,3,4]),
        function (left, right) {
          return left.mod(right).eq(0)
        }
      )
    //=>
    [
    {
    "left": 2 ,
    "right": 2
    } ,
    {
    "left": 8 ,
    "right": 2
    } ,
    {
    "left": 8 ,
    "right": 4
    } ,
    {
    "left": 12 ,
    "right": 2
    } ,
    {
    "left": 12 ,
    "right": 3
    } ,
    {
    "left": 12 ,
    "right": 4
    } ,
    {
    "left": 15 ,
    "right": 3
    } ,
    {
    "left": 20 ,
    "right": 2
    } ,
    {
    "left": 20 ,
    "right": 4
    } ,
    {
    "left": 21 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 2
    } ,
    {
    "left": 24 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 4
    }
    ]

RethinkDB will loop 27 times(9x3) and evaluate function to find rows. Because
of the evaluation, this function is slow.

Here is another real example with real data. Let's find all `foods` and its `compound_foods`.

    r.db("foodb")
      .table("foods")
      .innerJoin(
        r.db("foodb")
          .table("compounds_foods")
        , function(food, compound_food) {
          return food("id").eq(compound_food("food_id"))
        })
    //=>
    {
    "left": {
    "created_at": Wed Feb 09 2011 00:37:15 GMT-08:00 ,
    "creator_id": null ,
    "description": null ,
    "food_group":  "Vegetables" ,
    "food_subgroup":  "Cabbages" ,
    "food_type":  "Type 1" ,
    "id": 2 ,
    "itis_id": null ,
    "legacy_id": 2 ,
    "name":  "Savoy cabbage" ,
    "name_scientific":  "Brassica oleracea var. sabauda" ,
    "picture_content_type":  "image/jpeg" ,
    "picture_file_name":  "2.jpg" ,
    "picture_file_size": 155178 ,
    "picture_updated_at": Fri Apr 20 2012 09:39:54 GMT-07:00 ,
    "updated_at": Fri Apr 20 2012 16:39:55 GMT-07:00 ,
    "updater_id": null ,
    "wikipedia_id": null
    } ,
    "right": {
    "citation":  "DTU" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 13831 ,
    "created_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "creator_id": null ,
    "food_id": 2 ,
    "id": 15619 ,
    "orig_citation": null ,
    "orig_compound_id":  "0014" ,
    "orig_compound_name":  "Vitamin A, total" ,
    "orig_content":  "0.5E2" ,
    "orig_food_common_name":  "Cabbage, savoy, raw" ,
    "orig_food_id":  "0674" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit":  "RE" ,
    "orig_unit_expression": null ,
    "updated_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "updater_id": null
    }
    } {
    "left": {
    "created_at": Wed Feb 09 2011 00:37:15 GMT-08:00 ,
    "creator_id": null ,
    "description": null ,
    "food_group":  "Vegetables" ,
    "food_subgroup":  "Cabbages" ,
    "food_type":  "Type 1" ,
    "id": 2 ,
    "itis_id": null ,
    "legacy_id": 2 ,
    "name":  "Savoy cabbage" ,
    "name_scientific":  "Brassica oleracea var. sabauda" ,
    "picture_content_type":  "image/jpeg" ,
    "picture_file_name":  "2.jpg" ,
    "picture_file_size": 155178 ,
    "picture_updated_at": Fri Apr 20 2012 09:39:54 GMT-07:00 ,
    "updated_at": Fri Apr 20 2012 16:39:55 GMT-07:00 ,
    "updater_id": null ,
    "wikipedia_id": null
    } ,
    "right": {
    "citation":  "DTU" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 1014 ,
    "created_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "creator_id": null ,
    "food_id": 2 ,
    "id": 15630 ,
    "orig_citation": null ,
    "orig_compound_id":  "0038" ,
    "orig_compound_name":  "Niacin, total" ,
    "orig_content":  "0.522E0" ,
    "orig_food_common_name":  "Cabbage, savoy, raw" ,
    "orig_food_id":  "0674" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit":  "NE" ,
    "orig_unit_expression": null ,
    "updated_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "updater_id": null
    }
    }

It will run forever, because we have 888 documents in `food` table, and `10959` document
in `compound_foods` table. It has to run the predicate function
888 * 10959 = 9,731,592 time. On my laptop, it runs in:

C> Executed in 2min 25.86s. 40 rows returned, 40 displayed, more available

Basically `innerJoin` is equivalent of table scan in MySQL. We should avoid
using it on any significant data.

## outerJoin

`innerJoin` is an intersection of two sequences where a pair of documents sastify
a condition. How about something similar to an `left join` in SQL? Let's meet `outerJoin`

`outerJoin` will return all documents of left sequences. With each document,
it will try to match with every documents of right hand. If the pair sastify
a predicate function, the pair is returned. If not, the only document of left
sequence is returned. At very least, the finaly sequence will include all
document of left sequence. Using same data set, but for `outerJoin`:

    r.expr([2,5,8,12,15,20,21,24,25])
      .outerJoin(
        r.expr([2,3,4]),
        function (left, right) {
          return left.mod(right).eq(0)
        }
      )
    //=>
    [
    {
    "left": 2 ,
    "right": 2
    } ,
    {
    "left": 5
    } ,
    {
    "left": 8 ,
    "right": 2
    } ,
    {
    "left": 8 ,
    "right": 4
    } ,
    {
    "left": 12 ,
    "right": 2
    } ,
    {
    "left": 12 ,
    "right": 3
    } ,
    {
    "left": 12 ,
    "right": 4
    } ,
    {
    "left": 15 ,
    "right": 3
    } ,
    {
    "left": 20 ,
    "right": 2
    } ,
    {
    "left": 20 ,
    "right": 4
    } ,
    {
    "left": 21 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 2
    } ,
    {
    "left": 24 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 4
    } ,
    {
    "left": 25
    }
    ]

**5** and **25** were not divided by any of the number on right hand. Therfore,
the return document contains only left hand document.

## Name conflict

In SQL worlds, we can alias column to avoid conflict when joining. What
RethinkDB gives us, when we used `zip` command to merge the document? We
will loose the column on left sequence. We have several ways to address this.

Firstly, if we want to use `zip`:

    *  Removing conflict fields: By simply remove the field we don't want,
       we can get what we want.

    *  What if we want to keep both fields? We can rename it, using `map`.

Secondly, we don't have to use `zip`, and we can merge document itself with
`map`, and only keep what we want.

However, we are still not able to address this issues. Those are just work-around. Luckily,
RethinkDB team are aware of that and is working on it now[^collapse].

[^collapse]: https://github.com/rethinkdb/rethinkdb/issues/1855

## Using sub queries

### One to many relation

Almost above JOIN commands is operator on two sequence. What if we have exactly
a single document which we get by using `get` and we want to join some data.
If we think a bit, we can see that in RethinkDB, we can query whatever extra
data inside an anonoymous function. What if we query extra data inside those
function then merge it with parent document. It will has same effect as a JOIN.
Let's do it. Let's say we want to know flavors of Kiwi, a fruit that we never
eat. We had a table **compounds_flavors** which contains association of a
*compound* and a *flavor*. We have table *compounds_foods* which contains
association of a *compound* and a *food*. So basically, we can do this:

  * Given a food, we know its ID
  * Find all of its *compound* using **compound_foods** tables.
  * With each of compound, we can know its flavor, by query *compound_flavors* to find association with *flavors* table. 
    In other words, to find the *flavor_id* for that compounds.

First of all, we needs some index:

    // We need this index to look up by food_id on `compounds_foods`
    r.db('foodb').table('compounds_foods').indexCreate('food_id')

    // We need this index to find on `compounds_falvors` by compound_id
    r.db("foodb").table("compounds_flavors").indexCreate('compound_id')

With that index, let's build our query step by step. First, we select Kiwi,
its ID is *4*. Then calling *merge* command. 

    r.db("foodb")
      .table("foods")
      .get(4)
      .merge(function (food) {

        return {
          flavors: //flavor array here
        }
      })

Let's see what will we fill in **flavors** array. We will try to grab all of
its compound. That means all of *documents* of *compounds_foods* table where
its *food_id* is equal with main ID of kiwi.

    r.db("foodb")
      .table("foods")
      .get(4)
      .merge(function (food) {
        return {
          flavors:
              r.db("foodb").table("compounds_foods")
                  .getAll(food("id"),{index: "food_id"})
                  .concatMap(function(compound_food) {
                    //Return something flavor of compound here
                  })
                  .coerceTo("array")
        }
      })

Notice that we used `concatMap` so that it flattens array for us. We also used
 `coerceTo` to convert selection result to an array for `merge` command.
With each of document of *compounds_foods* we can baiscally get all of its 
flavor as following:

    r.db("foodb").table("compounds_flavors")
                        .getAll(compound_food("compound_id"), {index: "compound_id"})
                        .concatMap(function(compounds_flavor) {
                        return
                          r.db("foodb").table("flavors").getAll(compounds_flavor("flavor_id"))
                          .map(function (flavor) {
                            return flavor("name")
                          })
                        .coerceTo("array")
                        })
                            .coerceTo("array")

Putting together, we have this final giant, scary query:

    r.db("foodb")
      .table("foods")
      .get(4)
      .merge(function (food) {

        return {
          flavors: 
              r.db("foodb").table("compounds_foods")
                  .getAll(food("id"),{index: "food_id"})
                  .concatMap(function(compound_food) {
                      return 
                      r.db("foodb").table("compounds_flavors")
                        .getAll(compound_food("compound_id"), {index: "compound_id"})
                        .concatMap(function(compounds_flavor) {
                          return
                            r.db("foodb").table("flavors").getAll(compounds_flavor("flavor_id"))
                            .map(function (flavor) {
                              return flavor("name")
                            })
                            .coerceTo("array")
                        })
                        .coerceTo("array")


                  })
                  .distinct()
                  .coerceTo("array")
        }

      })

Before the final `coerceTo`, we also call `distinct` to eliminate duplicate.
And we got this result:

    {
        "created_at": Wed Feb 09 2011 00: 37: 15 GMT - 08: 00,
        "creator_id": null,
        "description": null,
        "flavors": [
            "alcoholic",
            "baked",
            "bay oil",
            "bitter",
            "bland",
            "bread",
            "cheese",
            "cheesy",
            "citrus",
            "coconut",
            "ethereal",
            "faint",
            "fat",
            "fatty",
            "medical",
            "metal",
            "mild",
            "odorless",
            "rancid",
            "slightly waxy",
            "soapy",
            "sour",
            "strong",
            "sweat",
            "sweet",
            "unpleasant",
            "waxy",
            "yeast"
        ],
        "food_group": "Fruits",
        "food_subgroup": "Tropical fruits",
        "food_type": "Type 1",
        "id": 4,
        "itis_id": "506775",
        "legacy_id": 4,
        "name": "Kiwi",
        "name_scientific": "Actinidia chinensis",
        "picture_content_type": "image/jpeg",
        "picture_file_name": "4.jpg",
        "picture_file_size": 110661,
        "picture_updated_at": Fri Apr 20 2012 09: 32: 21 GMT - 07: 00,
        "updated_at": Fri Apr 20 2012 16: 32: 22 GMT - 07: 00,
        "updater_id": null,
        "wikipedia_id": null
    }

While as the query looks giant and complex. The way to write is to drill down
each table at a time, using a map/concatMap to transform data.

### Many to many relation

Using of `outerJoin` and `innerJoin` are not efficient because they are not
using index at all. They are useful, like filter, powerful too but just not
very fast. As in *Chapter 5*, we used `concatMap` with `getAll` to query
data across tables, that is just an idea of *JOIN*. We should always avoid
`outerJoin` and `innerJoin` if possible and adopt `getAll` with `concatMap`.

In **inner join** section, it takes more than 2 minutes to run our query.
Let's try it again, find all *foods* and its *compounds_founds*, this time we
leverage an index with `getAll` and join data with `concatMap`

    r.db('foodb').table('foods')
      .map(function (food) {
        return food.merge({
          "compound_foods":
            r.db('foodb').table('compounds_foods')
              .getAll(food("id"), {index: 'food_id'})
              .coerceTo('array')
        })
      })

And how fast it runs:

C> Executed in 1.52s. 40 rows returned, 40 displayed, more available

Much better than using `innerJoin`.Compare to >2mins before, this is 
a major improvement. To really see how fast/slow a query
without index, you may want to put data on a spin disk(an external hard drive
for example), because SSD is usually fast and you may not notice. All of
my above example is using a SSD on  Macbook Pro (Retina, 13-inch, Mid 2014),
with process Interl Core i5 2.8ghz and 16GB RAM.

The key point is to ensure we get data using index. For each of document, we
join data by run other query in a `map`/`concatMap` function to merge/transform
extra data. The merge document is returned instead of original document

The main different between using sub query is that we have nested document
instead of **left** **right** field like in JOIN. However, via using some map or
transform command we can turn them into whatever we can imagine.

# Why map/concatMap is important

In SQL, we can basically join whatever. In RethinkDB, join is infact just a syntaxtic
sugar on top of `getAll` and `concatMap`. As you learn in *Chapter 5*, `map`/`concatMap`
allow you to transform data with its relation data in an associated table, by
querying extra data inside map function.

I once say that they are important and now I repeated again because they are
everything. `getAll` is just like *SELECT* in MySQL in term of how much
you have to use. And `getAll` is not very useful without a `map`.

# Wrap up

At the end of this chapter, we should know how to join based on these concepts:

  * Primary key: the ID field of document
  * Secondary index: join using secondary index
  * Sub queries: using merge, map/concatMap to join data
