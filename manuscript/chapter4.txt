-# Modifying data

We know how to fetch the data. But a database is useless without ability of
writing data. In this chapter, we will learn about writing data. We will
address database command, table command, and then document command
in this chapter.

# Database

All commands on database levels start at the top namespace `r` since they are
like genesis item in any database system. Let's start out journey by creating
a database. Remember, we need a database to hold everything.

## Create

Very simple. With example, you will get it easily.

    //Create database
    r.dbCreate("db1")
    #=>
    {
    "config_changes": [
    {
    "new_val": {
    "id":  "5e4a85fa-d867-4a93-aa01-2d08ed6f0b14" ,
    "name":  "db1"
    } ,
    "old_val": null
    }
    ] ,
    "dbs_created": 1
    }

If creating succesfully, we get back the object with `created` is always *1*.
**config_changes** will have **new_val** field is the database's config value.
**old_val** is always *null* becase this is a new database. **config value**
is the configuration for an individual database or table. What is the 
configuration? Usually, when we create any object in RethinkDB (a database, 
a table) we can pass a list of option to that creating command. That option
has to be stored somewhere and we should have ability to read it back.
For a database, configuration is just its name and its id. That's why you see
the id and name are returned in above query. We will learn more about this
configuration very quick in this chapter.

We can confirm by listing what we have:

    r.dbList()
    #=>
    [
    "foodb" ,
    "rethinkdb" ,
    "superheroes" ,
    "test"
    ]

Notice a special database call ***rethinkdb***? This is a special database that
is created by RethinkDB to hold meta data, configuration. It's very similar to
**mysql** database in a MySQL server. Remember the configuration of `dbCreate`
function? Those configuration is stored in table `db_config` inside this
database `rethinkdb`.

## Drop

So we got the default test and db1 is what we just have. Since we don't use db1,
let's delete it to keep our database clean.

    r.dbDrop('db1')
    #=>
    {
    "config_changes": [
    {
    "new_val": null ,
    "old_val": {
    "id":  "5e4a85fa-d867-4a93-aa01-2d08ed6f0b14" ,
    "name":  "db1"
    }
    }
    ] ,
    "dbs_dropped": 1 ,
    "tables_dropped": 0
    }

Very similar with `dbCreate` but in an opposite way. Now `new_val` is **null**
because the database is no longer existed. **old_val** is the id and name of
old database, or the old configuration of database. 

# Table

Tables have to sit inside a database, therefore, all table commands have to call
on a database. When you don't explicit specify a database to run on with `r.db`,
the current database will be the base for table manipulation.

## Create

The syntax to create a table is

    db.tableCreate(tableName[, options])

The second parameter is optional. This is what we consider configuration for
a table. It's similar to database configuration. But table configuration is
much richer. Some important ones are:

*primaryKey

: the name of primary key. As I mentioned before, default name of primary key is
**id**. Using this option, you can change that default behavior like we used
`uuid` with our input_polls table.

*durability

: accept value of *soft* or *hard*. *soft* means the writes will be
acknowledged by server immdediately, and data will be flushed to disk in the
background. If that flushing fail, we may not know. The default behaviour is
to acknowledge after data is written to disk. That means *hard*. It's default
because it's much safety.
When we don't need the data to be consitent, such as writing a cache, or an
unimportant log, we should set durability to soft to speed up the writing.
However, for any important, serious data, keep it default.

RethinkDB stores configuration of each table in a special table call
**table_config** inside database **rethinkdb**.

## List table

To list what table we have inside a database, we use `tableList` command. It's
similar to **SHOW TABLE** in MySQL.

    r.db("foodb").tableList()
    //=>
    [
    "compound_synonyms" ,
    "compounds" ,
    "compounds_flavors" ,
    "compounds_foods" ,
    "compounds_health_effects" ,
    "flavors" ,
    "foods" ,
    "health_effects" ,
    "t1" ,
    "users"
    ]

## Drop table

To get rid of the table, use `tableDrop` command. 

    r.db("foodb").tableDrop("t1")
    //=>
    {
        "config_changes": [{
            "new_val": null,
            "old_val": {
                "db": "foodb",
                "durability": "hard",
                "id": "d20fe79e-9e90-4625-95f7-c9e1953bf773",
                "name": "t1",
                "primary_key": "id",
                "shards": [{
                    "primary_replica": "SimplyRethinkDB",
                    "replicas": [
                        "SimplyRethinkDB"
                    ]
                }],
                "write_acks": "majority"
            }
        }],
        "tables_dropped": 1
    }

Very similar to `dbDrop`, we also have **config_changes**. **new_val** always
null because the table is gone now. **old_val** is the configuration of removed
table. Table configuration is usually what we passed in when we create it with
**tableCreate**.

We see that some **db** and **table** command returns **config_changes**. Let's
discover where those configs are stored.

# System table

Usually a database server have to keep some meta data, or configuration
information somewhere else. In case of RethinkDB, it stores those data in
**rethinkdb** data. Let's discover this database: 

    r.db("rethinkdb").tableList()
    [
    "cluster_config" ,
    "current_issues" ,
    "db_config" ,
    "jobs" ,
    "logs" ,
    "server_config" ,
    "server_status" ,
    "stats" ,
    "table_config" ,
    "table_status"
    ]

The name of each table should suggest what it contains. Let's inspect **server_config**

    r.db("rethinkdb").table("server_config")
    //=>
    {
    "cache_size_mb":  "auto" ,
    "id":  "fdc5dade-2f0c-498f-8c4b-59ad0d976471" ,
    "name":  "Vinh_local_u27" ,
    "tags": [
    "default"
    ]
    }

Let's change our server name:

  r.db("rethinkdb").table("server_config")
    .get("fdc5dade-2f0c-498f-8c4b-59ad0d976471")
    .update({name: "SimplyRethinkDB"})

You will notice that the Admin UI will change the server name:

![Server name changes to SimplyRethinkDB](images/chapter4/servername_ui.png)

By modifying those table, we change the configuration of our server. We can get
RethinkDB version by querying `server_status`.

    r.db("rethinkdb").table("server_status")("process")("version")

In other words, those system table refelects information related to how the
system operates. We can query to fetch or modify system information.

We can get configuration that we set when creating table with `tableCreate` of
any table:

    r.db("rethinkdb").table("table_config")
    //=>
    {
    "db":  "foodb" ,
    "durability":  "hard" ,
    "id":  "2e41fc0b-ea5e-4460-bd3b-5d33a5ec49af" ,
    "name":  "health_effects" ,
    "primary_key":  "id" ,
    "shards": [
    {
    "primary_replica":  "SimplyRethinkDB" ,
    "replicas": [
    "SimplyRethinkDB"
    ]
    }
    ] ,
    "write_acks":  "majority"
    } {
    "db":  "foodb" ,
    "durability":  "hard" ,
    "id":  "3fbf59ad-35df-445c-9fa9-be19071d38d7" ,
    "name":  "compounds_flavors" ,
    "primary_key":  "id" ,
    "shards": [
    {
    "primary_replica":  "SimplyRethinkDB" ,
    "replicas": [
    "SimplyRethinkDB"
    ]
    }
    ] ,
    "write_acks":  "majority"
    }

Looking at the above result, we can see that table `health_effects` of database
`foodb` has **primary_key** is **id**, and **write_acks** is **majority**.

You can have more fun and some deep understanding under the hood by inspecting
those tables.

# Document

After creating database and creating table, we can start inserting document into
table.

## Insert

As you can guess, we will start from the database, chain the table, and use
`*insert*` method to insert a document into the table. Eg

    r.db('test').table('input_polls').insert({
      id: 'foo',
      Day: 120,
      Date: 'May 2',
      Dem: '49'
    })

    #=>
    {
      "deleted": 0 ,
      "errors": 0 ,
      "generated_keys": [
      "13556cd8-034c-4c0e-91c0-666230740121"
      ] ,
      "inserted": 1 ,
      "replaced": 0 ,
      "skipped": 0 ,
      "unchanged": 0
    }

The return object contains the following attributes: 

inserted
: the number of documents that were succesfully inserted.

replaced
: the number of documents that were updated when upsert is used.

unchanged
: the number of documents that would have been modified, except that the new value was the same as the old value when doing an upsert.

errors
: the number of errors encountered while performing the insert.

first_error
: If errors were encountered, contains the text of the first error.

deleted, skipped
: 0 for an insert operation.

generated_keys
: a list of generated primary keys in case the primary keys for some documents were missing (capped to 100000).

warnings
: if the field generated_keys is truncated, you will get the warning: "Too many generated keys (<X>), array truncated to 100000.".
old_val
: if returnVals is set to true, contains null.
new_val
: if returnVals is set to true, contains the inserted/updated document.

Notice the generated_keys. If you insert a document without set a value for
primary key, whose field name is `*id*` by default, RethinkDB will generate an
UUID[^uuid] for it and return here.

[^uuid]: http://en.wikipedia.org/wiki/Universally_unique_identifier

With our example, we can retreive back the document again.

    r.table('input_polls').get('13556cd8-034c-4c0e-91c0-666230740121')
    #=>
    {
        "Date":  "May 2" ,
        "Day": 120 ,
        "Dem":  "49" ,
        "id":  "foo" ,
        "uuid":  "13556cd8-034c-4c0e-91c0-666230740121"
    }

Notice the `*uuid*` field? Our table has primary field is `*uuid*` and its value
is set automatically by RethinkDB. 



### Multi insert

If you have a large data set, you may want to do a batch insert.

@TODO
example batch insert

### Effect of **durability**

Let's see the difference of **durability**. We will insert a big document.

First, I will create a temporary table
    r.tableCreate("git")

Then insert data, to have a big amount of data. I use `http`, which is a
command that fetch external JSON data.

    r.table('git').insert(
      r.http('https://api.github.com/repos/rethinkdb/rethinkdb/stargazers')),
      {durability:soft}
    )
    Executed in 773ms. 1 row returned

Now, if I turn on **durability**.

    r.table('git').insert(
      r.http('https://api.github.com/repos/rethinkdb/rethinkdb/stargazers')),
      {durability:soft}
    )
    Executed in 1.18s. 1 row returned


## Update

To make it easier, you can think of updating like selecting data, then change
their value. We chain `update` method from a selection range to update its data.
With that being said, we can update one or many documents at a time. Similar to
MySQL, we can update a full table, or update only rows that sastify a **WHERE**
condition.

Think of modification is like a transform process where you get a list of
document(one or many), then transform by adding fields, rewrite value for some fields.
By that definition, it doesn't matter if you update one document, or many 
document.As long as you have an array, or a stream of data, you can update them
all.

For example, to update an attribute for a single element

    // Let create a fake user
    r.db("foodb").table("users")
      .insert({id: "user-foo1", name: "foo", age: 12})
    // Let update age and add a new field
    r.db("foodb").table("users")
      .get("user-foo1")
      .update({
        age: 13,
        gender: "f"
      })
    //=>
    {
      "deleted": 0 ,
      "errors": 0 ,
      "inserted": 0 ,
      "replaced": 1 ,
      "skipped": 0 ,
      "unchanged": 0
    }

RethinkDB returns an object for the updating result. We can look into `replaced`
field to see if the data is actually updated. If we re-run the above command,
nothing is replaced and we will got 1 `unchanged`.

    r.table('input_polls').get('13556cd8-034c-4c0e-91c0-666230740121')
      .update({
          'Dem': 120
      })
    //=>
    {
      "deleted": 0 ,
      "errors": 0 ,
      "inserted": 0 ,
      "replaced": 1 ,
      "skipped": 0 ,
      "unchanged": 0
    }

That's just how awesome RethinkDB is. All query result is very verbose. And
easy to understand.

In above example, you can see when we update **age**, we also add a new field
**gender**. The updating process can be understand as a merge process of
return values from update function or update expression into current existed
document. Let's verify if **gender** field are really there:

    r.db("foodb").table("users")
      .get("user-foo1")
    //=>
    {
      "age": 13 ,
      "gender":  "f" ,
      "id":  "user-foo1" ,
      "name":  "foo"
    }

We can also update nested field. Let's add an address field:

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({
        "address" : {
        country: "USA",
        state: "CA",
        city: "Cuppertino",
        street: "Infinite Loop",
        number: "1",
        ste: "1205"
      }
      })
    //=>
    {
      "deleted": 0 ,
      "errors": 0 ,
      "inserted": 0 ,
      "replaced": 1 ,
      "skipped": 0 ,
      "unchanged": 0
    }

**replaced** is 1, that means we update succesfully. Now, let's say I moved,
I can change the address:

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({
        "address" : {
        ste: 880,
        number: 11
      }
      })
    //=>
    {
      "deleted": 0 ,
      "errors": 0 ,
      "inserted": 0 ,
      "replaced": 1 ,
      "skipped": 0 ,
      "unchanged": 0
    }

Here, we are updating field `ste` of field `address`.

    r.db("foodb").table("users")
      .get("user-foo1")
    //=>
    {
      "address": {
      "city":  "Cuppertino" ,
      "country":  "USA" ,
      "number":  11 ,
      "state":  "CA" ,
      "ste":  880 ,
      "street":  "Infinite Loop"
      } ,
      "age": 13 ,
      "gender":  "f" ,
      "id":  "user-foo1" ,
      "name":  "foo"
    }

The value of the updated field, as you can see in above example, is a single
value.

#### Update option

`update` command receive some options that you can pass. In JavaScript, you can
pass option object as second parameter. In Ruby, you can use optional keyword.
Such as in JavaScript:

    r.table("posts").get(1).update({
        num_comments: r.js("Math.floor(Math.random()*100)")
    }, {
        nonAtomic: true
    })

Here, `{nonAtomic: true}` is out option. In Ruby, it's more elegant due:

    r.table("posts").get(1).update({
        :num_comments => r.js("Math.floor(Math.random()*100)")
    }, :non_atomic => true)

We have 3 options parameters:

  * *durability*: possible values are hard and soft. You already know what it does. However, setting it here override durability default of tables
  * *non_atomic*: you should also know what it does. If not, coming back chapter2.

So we know the option. Let's move on. In this section, we learn how to update
value for a field, update nested value. What if the field contains an array?
How can we append new element. Or how to
update value which is the result of other ReQL command. Let's move to next
section.

### Update data for complex field

First, we see that an user can have many address. Right now, our *address*
field is a single object. Let's make it an array so it can accepts many
address. Using previous array that we created.

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({
        address: [r.row("address")]
      })

Here we are using `r.row`, it allows access to current document we are
referencing to. We turn **address** into an array by wrap it in `[]`
to turn it into array.

Now, we got `address` is an array with a single address, How do we add more
data into that array. The simple form, we can pass an value to the `update`.
First, we get the value of current address, append a new element using what
our language offer. In JavaScript code, we may have:

    addresses = r.db("foodb").table("users")
              .get("user-foo1")("address")
    addresses.push(new_add_ress)
    r.db("foodb").table("users")
      .get("user-foo1")
      .update({address: addresses})

That's work but it's very inefficent. For example, if we have to append a new
element to an array for 1000 users. We have to fetch the data, change it,
update by sending new array again.

Also a more important issue is updating lock. When we are retriving data, alter
it
on client side, push back data to database. During the time since we get the
data and push it back. The server may changes the data and we didn't aware of
it in first query to retrieve data, now when we push back, we override that new
changes. Image this, we have 2 admins on the sites, who are trying to edit an
user at the same time to update user's address.

First, admin 1 retrieve data, add new address B and push it back. For whatever
reason, admin 2 retrieve data, right after admin 1 retrieve
data, then add new address B and update it, but before admin 1 push it back. 
So when admin 1 pushs data back, the changes admin 2 created is override.

It's would be great if we can move the logic into RethinkDB and let's
RethinkDB handles lock for it. Just like how in SQL we can do:

    UPDATE TABLE user SET login=login+1

We tell MySQL to increment value of login by 1 instead of doing that outself.
Luckily, we have that in RethinkDB. Some of them falls under **Document
manipulation**[^Documentmanipulation] section on RethinkDB docs. They allow us
do some logic to the document.

[^Documentmanipulation]: http://www.rethinkdb.com/api/ruby/pluck/

Our example above can be written using `append`. **append** command add a new
element to array.

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({
        address: r.row("address")
        .append({country: "Vietnam", 
                    city: "Hue", 
                          street: "Tran Phu",
                    number: "131"})
      })
    //=>
    {
      "deleted": 0 ,
      "errors": 0 ,
      "inserted": 0 ,
      "replaced": 1 ,
      "skipped": 0 ,
      "unchanged": 0
    }

What if an user has not **address** field on it yet? Well, an error will be
thrown out. let's try:

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({
        another_address_field: r.row("another_address_field")
        .append({country: "Vietnamnam", 
                    city: "Hue", 
                    street: "Tran Phu",
                    number: "131"})
      })
    //=>
    {
        "deleted": 0,
        "errors": 1,
        "first_error": "No attribute `another_address_field` in object: {
            "address": [{
                "city": "Cuppertino",
                "country": "USA",
                "number": 11,
                "state": "CA",
                "ste": 880,
                "street": "Infinite Loop"
            }, {
                "city": "Hue",
                "country": "Vietnam",
                "number": "131",
                "street": "Tran Phu"
            }],
            "age": 13,
            "gender": "f",
            "id": "user-foo1",
            "name": "foo"
        }
        " ,
        "inserted": 0,
        "replaced": 0,
        "skipped": 0,
        "unchanged": 0
    }

To avoid that, we have tell RethinkDB what value should be used when that
field doesn't exist. Such as for an array, we can consider that value is
an empty array. For a string we can consider that value is an empty string.
For a positive number, that can be zero.

We use `defaul(default_value)` command for this purpose. Let's try it:

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({
        another_address_field: 
                r.row("another_address_fieldess_field")
                  .default([])
                  .append({country: "Vietnamnamam", 
                    city: "Hue", 
                    street: "Tran Phu",
                    number: "131"})
      })
    //=>
    {
    "deleted": 0 ,
    "errors": 0 ,
    "inserted": 0 ,
    "replaced": 1 ,
    "skipped": 0 ,
    "unchanged": 0
    }

When we call command `default` on a value or a sequence, it will try to evalute
to the default value in case of non-existence error for the value. We can verify
address again:

    r.db("foodb").table("users")
      .get("user-foo1")
    //=>
    {
        "address": [{
            "city": "Cuppertino",
            "country": "USA",
            "number": 11,
            "state": "CA",
            "ste": 880,
            "street": "Infinite Loop"
        }, {
            "city": "Hue",
            "country": "Vietnam",
            "number": "131",
            "street": "Tran Phu"
        }],
        "age": 13,
        "another_address_field": [],
        "gender": "f",
        "id": "user-foo1",
        "name": "foo"
    }

So we had `append` to add element at the end of array, we can also use
`prepend`. It adds a new element to an array but at the top.

Take another example, we want to count how many **like** an user has. We will
use a fiel call **like** and we increase it by 1 whenever someone like the user.

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({like: r.row("like").add(1)})

You notice that we have to use `add` command instead of writing like:

    like: r.row("like") +1

Because these expressions are evaluated on RethinkDB server, not on client. When I
first learn RethinkDB, somehow I didn't understand it. I'm probably dumb. I
keep thinking those run on client and it makes my life harder. So I'm trying
to remind this several time through the book just in case someone confuse
like me. In some language that support operator overloading, you may use 

    like: r.row("like") + 1

That's because the driver override **+** operator to make it easy to write
expression. They are still serialized to ReQL syntax by driver.

Now, with above **update* command, we got error, which is expeteced:

    {
        "deleted": 0,
        "errors": 1,
        "first_error": "No attribute `like` in object: {
            "address": [{
                "city": "Cuppertino",
                "country": "USA",
                "number": 11,
                "state": "CA",
                "ste": 880,
                "street": "Infinite Loop"
            }, {
                "city": "Hue",
                "country": "Vietnam",
                "number": "131",
                "street": "Tran Phu"
            }],
            "age": 13,
            "another_address_field": [{
                "city": "Hue",
                "country": "Vietnam",
                "number": "131",
                "street": "Tran Phu"
            }],
            "gender": "f",
            "id": "user-foo1",
            "name": "foo"
        }
        " ,
        "inserted": 0,
        "replaced": 0,
        "skipped": 0,
        "unchanged": 0
    }

We have to set a default value for it. Let's default to 0. 

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({like: r.row("like").default(0).add(1)})
    // Get back like
    r.db("foodb").table("users").get("user-foo1")("like")
    //=>
    1

`add` is not limited on numeric data, it works on **array**, **string** too.
I will leave that part for you as an exercise.

Now we know how to work with an array as value of a field. Let's dive into how
to work with an object as a value of a field. Considering that we have this:

    r.db("foodb").table('users')
      .get('user-foo1')
      .update({
        social: {twitter: "kureikain"}
      })
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "replaced": 1 ,
        "skipped": 0 ,
        "unchanged": 0
    }

The `social` field is an object now. Now, the user enters his facebook username
so we we want to add a new field **facebook** to **social** field to denote the
**facebook** account of user. We can not use `append` or `add` on an object.
For object, we use `merge` to add or override a field.

    r.db("foodb").table('users')
      .get('user-foo1')
      .update({
        social: r.row('social').default({}).merge({facebook: "kureikain"})
      })
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "replaced": 1 ,
        "skipped": 0 ,
        "unchanged": 0

    }

Same as `append`, we also have to set a default value to handle non-existence
error. Since we are working with an object, we set its default value to empty
object: `{}`. `merge` overide existed key with new value in the object you
are passing, or create new key from the passing object.

    r.db("foodb").table('users')
      .get('user-foo1')
      .update({
        social: r.row('social').default({}).merge({facebook: "kureikain2", twitter: "kureikain2"})
      })
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "replaced": 1 ,
        "skipped": 0 ,
        "unchanged": 0

    }
    
    // Select it back
    r.db("foodb").table('users')
      .get('user-foo1')("social")
    //=>
    {
      "facebook":  "kureikain2" ,
      "twitter":  "kureikain2"
    }

Cool, so we know how to add new fields or override old fields. But do you
notice they when a field contains an object, they are actually nested field. 
So we can easily update use nested field knowledge before instead of using
`merge` command:

    r.db("foodb").table('users')
      .get('user-foo1')
      .update({
        social: {facebook: "kureikain3", github: "kureikain"}
      })

It's really up to you to use `merge` or the nested field style. I usually using
nested field style when doing simple update, and `merge` when I want to merge
the document to other result from other ReQL function. But that's just opinion.

### Update multiple documents

Instead of select a single document and update one by one, you can update a
bunch of documents by calling `update` on a table or a stream, a selection.
All are same like what we do above, but instead of applying update to a single
document, it updates all element in the stream.

    r.table.filter(r.row('Day').gt(1) && r.row('Day').lt(90))
      .update({quarter: 1})
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "replaced": 55 ,
        "skipped": 0 ,
        "unchanged": 0
    }

### ReQL inside the updated object

As you notice, we not only pass value into an updated object, but also passing
ReQL into updated object. As long as it can be evaluated like we increased **like**
to 1 with:

    r.db("foodb").table("users")
      .get("user-foo1")
      .update({like: r.row("like").default(0).add(1)})

However, `r.row` has a limit. It cannot be called on nested query. Assume that
we have a **friends** table that we can create with below query:

    // First, creata table
    r.db("foodb").tableCreate('friends')

    // Insert some faked data
    r.db("foodb").table("friends")
      .insert([{
        friend1_id: '12063f5f-4289-4a4b-b668-0e4a90861575',
        friend2_id: 'user-foo1'
      },
      {
        friend1_id: '8d4bcd47-3f7f-4670-a31c-2b807e3f7caf',
        friend2_id: 'user-foo1'
      }])

So we can see that our user with id **user-foo1** has 2 friends. It will not
very efficient if we have to count this over and over. So we are going to count
this and update **users** table with a field **friend_count**.

To count, we can get a sequence of **friend2_id**, and `count` how many items
has same value as current user id, by passing a value to `count` function. When
we pass a value to `count`, it only counts the document equal to that value.
Here, We are trying use `r.row` to reference to current user.

    r.db('foodb').table('users')
      .get('user-foo1')
      .update({
        friend_counts: r.db('foodb').table('friends')('friend2_id').count(r.row('id'))
      })

If we run above query we will get this error


C>    RqlCompileError: Cannot use r.row in nested queries.  Use functions instead in:
C>    r.table("foodb").get("user-foo1").update({friend_counts: r.db("foodb").table("friends")("friend2_id").count(r.row("id"))})

The reason for this error is because RethinkDB doesn't know which query to base
`r.row` on? Is it the main query, table **users**, or sub query, table
**friends**. Luckily, We can use an anynoymous function to solve this. Function
allows access to current document but it solve problem of `r.row` because it 
clearly binds to a sequence.

### Expression

Let's get some basic knowledge then we will come back to the previous example.

Beside passing an object into `update` command, we can also pass an expression or 
a function which returns an object. RethinkDB will evaluate it, get the object
result and use that value for `update` command. It comes in useful when you 
have some logic on your document related to the updating. In case of function,
the function receive first parameter is the current document.

With previous example, we can re-write using function:

    r.db('foodb').table('users')
      .get('user-foo1')
      .update(function (user) {
        return {
          friend_counts: r.db('foodb').table('friends')('friend2_id').count(user("id"))
        }
      })

Then, we got an error:

    RqlRuntimeError: Could not prove function deterministic.  Maybe you want to use the non_atomic flag? in:
    r.db("foodb").table("users").get("user-foo1").update(function(var_58) { return {friend_counts: r.db("foodb").table("friends")("friend2_id").count(var_58("id"))}; })

Well, this is because the updating isn't **atomic**[^atomic1][^atomic2]

[^atomic1]: http://rethinkdb.com/docs/architecture/#query-execution
[^atomic2]: http://rethinkdb.com/docs/architecture/#query-execution

Atomic update mean that an update to a document either succesfull,
or fail and no change is made. Such as we update two fields of a document,
first field update is succesfull but second field fail to update. Atomic
guarantees that both of fields will be sucesfully updated to new value.
Any update happen on a single JSON document is guaranteed to be atomic city.
So what is a non-atomic update? Non atomic update is setting value to
result of executing JavaScript code, random values, and values obtained as a
result of a subquery

T> non-atomic updates
T>
T> A good way to remember what is non-atomic update is that they are usually
T> value which cannot be predicate such as random values, result of other query

To run a non-atomic update, we have to clearly tell RethinkDB that with `nonAtomic`
option:

    r.db('foodb').table('users')
      .get('user-foo1')
      .update(function (user) {
        return {
          friend_counts: r.db('foodb').table('friends')('friend2_id').count(user("id"))
        }
      }, {nonAtomic: true})
    //=>
    {
    "deleted": 0 ,
    "errors": 0 ,
    "inserted": 0 ,
    "replaced": 1 ,
    "skipped": 0 ,
    "unchanged": 0
    }

We can verify the update really succesfully:

    r.db('foodb').table('users')
      .get('user-foo1')('friend_counts')
    //=>
    2

So we can see that in RethinkDB, we have to opt-in to use some features. Later
on, we know that we have to manually passing an index name to use it. That may
a little bit verbose at first. But that helps you understand query and let you
know what you are doing here.

Updating with function is really similar to passing object to update function.
We have to return an JSON object with key-value similar to the JSON document
that we pass directly to **update** command.

We can name the parameter of function to whatever. The name isn't important. It
is just like a callback function, in what RethinkDB will pass the real value
of current document to it when invoke that function. What we can do with `r.row`
we can mostly do with that parameter. Such as getting value of field with.
Let's change **user** to *u* and see if it works:

    r.db('foodb').table('users')
      .get('user-foo1')
      .update(function (u) {
        return {
          friend_counts: r.db('foodb').table('friends')('friend2_id').count(u("id"))
        }
      }, {nonAtomic: true})

Let's do one more complex example. If an users has more than 10 **friends**, we
set a field **social_status** to *extrovert*, otherwise, it's *introvert*.

    r.db('foodb').table('users')
      .get('user-foo1')
      .update(function (user) {
        return {
          social_status: r.branch(user('friend_counts').gt(10), 'extrovert', 'introvert')
        }
      }, {nonAtomic: true})

Here we are using a new command `r.branch`. It's like an `IF` in MySQL. If the
first argument is TRUE, the second argument is the return value, otherwise the
third argument. We use `user('friend_count')` to get value of `friend_count`
as you know. We calling `gt` command on it. `gt` means greater, it returns
**TRUE** if the value is greater than what we pass to `gt`.



When using a function, the parameter pass into function will be the current
visited document. Therefore, you can use many document manipulation command in
it such as: pluck, without, merge, append, prepend. Just remember this, so
you know what you can do with that parameter.

#### Expr

`expr` is a normal function but I think they are important and will help us
achive many crazy things so I cover them here.

What `expr` does is tranform a native object from host language into ReQL
object. For example, if a RethinkDb funciton can be call on array or sequence,
we cannot write something like this: `[e1, e2].nth(2)`, RethinkDB will throw an
error on [e1, e2]

    ["e1","e2"].nth is not a function

What we have to do is somehow convert the array that we write in native
language into RethinkDB data type. To do that, we simply wrap them in `expr`

A real example when I'm writing this book is I want to randomize generate
faked data for `users` table on `gender` field. I do this with:

    r.db("foodb").table("users")
      .update({
        gender: r.expr(['m', 'f']).nth(r.random(0, 2))
      }, {nonAtomic: true})

It means that for every document of `users` table, I want to set their gender to
either `m` or `f` randomly. I create a two element array `[m, f]`, turn them
into ReQL object with `expr`, so that I can call `nth` on them, passing a random
number of either 0 or 1.


let's try a more complex example to generate some data. We want to r

    r.db("foodb").table("users")
      .update({
          eatenfoods: r.db("foodb").table("foods").sample(r.random(0,
10)).getField('name')
        },
        {nonAtomic: true}
      )

For every document, we try to find a number of random food from `foods` table,
get only its name and return the array, and assign to `eatfoods`

Now, we have `eatenfoods` field. Let's say we want to create a field contains
the foods that an user has eaten, and his or her most favourite foods (first element
in `favfoods` field)

    r.db("foodb").table("users")
      .update({
        eateanorlike : r.add(r.row("eatenfoods"), [r.row("favfoods").nth(0)])
      }, {nonAtomic: true})

By combine ReQL expression, looking at its API and find approriate function,
we can achieve what we want. In the above example, we know we want to concat two
arrays from `eatenfoods` and first item of `favfoods`. We used `r.add`. We have
to wrap `r.row("favfoods").nth(0)` in `[]` because `nth()` return a document,
where as `r.add` expects array, so we wrap it in `[]`.

Before we continue, let's remove junk data:

    r.db("foodb").table("users").replace(r.row.without('eateanorlike'))

We also didn't have an `age` field on those user table. Let's generate some fake
data for it so we can play around later

    r.db("foodb").table("users")
      .update({
        age : r.random(8, 90)
      }, {nonAtomic: true})
    #=>
    {
    "deleted": 0 ,
    "errors": 0 ,
    "inserted": 0 ,
    "replaced": 152 ,
    "skipped": 0 ,
    "unchanged": 0
    }

By using function or expression, we can update document in a complex way

### Return Values

Sometimes, it can be useful to get back the updated document. This way you can
verify the result, without issuing a sub sequent `get` command. We just need to
set `returnVals` flag to true in option parameter of `update` command. Same
example:

    r.table('input_polls').get('13556cd8-034c-4c0e-91c0-666230740121')
      .update(function (poll) {
        return {
          same_day_count: r.table('input_polls')('Date').count(poll('Date'))
        }
      }, {nonAtomic: true, returnVals: true})
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "new_val": {
            "Date": "May 2" ,
            "Day": 120 ,
            "Dem": 120 ,
            "New Value": 1 ,
            "authors": [
                "foo" ,
                "bar"
            ] ,
            "id": "foo-bar" ,
            "reviewer": {
                "age": 25 ,
                "name": "Vinh" ,
                "state": "CA"
            } ,
            "same_day_count": 1 ,
            "type": "normal" ,
            "uuid": "13556cd8-034c-4c0e-91c0-666230740121" ,
            "views": 100
        } ,
        "old_val": {
            "Date": "May 2" ,
            "Day": 120 ,
            "Dem": 120 ,
            "New Value": 1 ,
            "authors": [
                "foo" ,
                "bar"
            ] ,
            "id": "foo-bar" ,
            "reviewer": {
                "age": 25 ,
                "name": "Vinh" ,
                "state": "CA"
            } ,
            "same_day_count": 1 ,
            "type": "normal" ,
            "uuid": "13556cd8-034c-4c0e-91c0-666230740121" ,
            "views": 100
        } ,
        "replaced": 0 ,
        "skipped": 0 ,
        "unchanged": 1
    }

The old value and value are returned in key `old_val` and `new_val`
correspondingly.

## Replace

To remove one or many fields from document, we cannot use `update` anymore.
We can set a field to `null` value(null, nil depends on your language) to make
it become null. But they key is still in the document with a `null` value.

We have to use `replace` method to replace it with a new document. The
new document is constructed from old document without the data we want to
eliminate.

    r.table('input_polls').get('13556cd8-034c-4c0e-91c0-666230740121')
      .replace(r.row.without('lol_author'))
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "replaced": 1 ,
        "skipped": 0 ,
        "unchanged": 0

    }

We can replace an entirely new document. However, the primary key cannot be
updated. It has to be same with the current primary key. An attempt to change
the primary key will caused an error **Primary key `uuid` cannot be changed**


    r.table('input_polls').get('13556cd8-034c-4c0e-91c0-666230740121')
      .replace({

        "Date": "May 2" ,
        "Day": 120 ,
        "Dem": 120 ,
        "New Value": 1 ,
        "authors": [
            "foo", "bar"
        ] ,
        "id": "foo-bar" ,
        "uuid": "13556cd8-034c-4c0e-91c0-666230740121" ,
        "views": 100
    })
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "replaced": 1 ,
        "skipped": 0 ,
        "unchanged": 0

    }



What if we want to remove an attribute of document? Well, let's set it to
`null`. Depend on your language, you have to use your null value such as in
Ruby, it's `nil`.

    r.table('input_polls').get('13556cd8-034c-4c0e-91c0-666230740121')
      .update({
          'Dem': null
      })
    //=>
    {

        "deleted": 0 ,
        "errors": 0 ,
        "inserted": 0 ,
        "replaced": 1 ,
        "skipped": 0 ,
        "unchanged": 0
    }


## Delete

Just go ahead and type those command if you want to. We can at any point, reset
to the original data set.

To remove one ore more document, use ReQL to select what we want and
execute `*delete*` on them.

This will delete a single document. 
    r.table('input_polls').get('id').delete()

Let clear out the vote from florda on may

    r.table('input_polls').filter(function (row) {
      r.row()
    })

Or just wipe an entire table

    r.table().delete()


`delete` method accepts an optional object with:

  * durability: 'hard' or 'soft'. default 'hard' and will override the value of
run.
  * returnVals: 'false' or true. True mean if the document fail to removed for
any reason, it will be returned to your result set. 

## Sync

As you known in the previous chapter, with value of `durability` as 'soft' the
write isn't guarantees to be written to the permanent storage. So after doing a
bunch of those `soft durability`, you may want to say `Hey, I am done all task,
let's make sure you write those change` you can call sync

  r.table('t').sync().run(connection, function () {
    console.log('Syncing is done. All data is safe now')
  })

A sync will run the callback will be called when all change are written to disk.

# Wrap up

Some important concept you should remember:

  * atomicity
