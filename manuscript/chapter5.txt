-# Reading Data Advanced

## Index

Soon enough you will realize that `filter` is slow. If you have a table
with more than 100,000 records, `filter` stops working. All of that is because
we haven't used index yet. Without an index, we cannot even order data.

    r.db("foodb").table("compounds_foods").orderBy(r.desc("id"))
    #->
    RqlRuntimeError: Array over size limit `100000` in:
    r.db("foodb").table("compounds_foods").orderBy(r.desc("id"))
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Without an index, RethinkDB holds all data in memory and sorts or filters in
memory. A limit has to lie somewhere else. 100,000 is the magic number of the limit
RethinkDB set to read data without index.


In order to properly fetching data, we have to create an Index. And in real application, we almost always ending up creating index on MySQL  to fetch data efficiently. 

We have two kinds of indexes in RethinkDB

* primary index: our ID key is this. This index is created automatically by
RethinkDB. Coming back to the above query, if we change it to use primary `index`

    r.db("foodb").table("compounds_foods").orderBy({index: r.desc("id")})

`id` field is always indexed automatically.

* secondary index:

Seconday index is the index we created ourselve on one or many fields. Secondary
index can be simple, just index the value of fields directly, or doing some
pre-calculate on data before indexing.

While index helps to decrease the reading time, it decreases writing time, and also cost
storage space. It reduces write performance because whenever we insert a
document, the index has to be calculated and written into the database.

RethinkDB supports those kinds of index:

*Simple
:indexes based on the value of a single field.
*Compound
:indexes based on multiple fields.
*Multi 
:indexes based on arrays of values.
*Indexes 
:based on arbitrary expressions.

So now you know what index is. But the sad news is that filter cannot use those secondary index. For that purpose, we have to use other functions: `getAll` and `between`. 
### Creating index

Let's start with simple index first.

## Simple index

As its name, simple index is simply a single field. Let's say, we want to find all `compounds_foods` whose name contains `banana`. We cannot use `filter` here because this table has more than 100,000 item. `filter` also doesn't use index. Let's meet `getAll`. `getAll` grabs all documents where a given key match the index which we specified.

First, we create index follow this syntax

    table.index_create(index_name[, index_function][, :multi => false]) → object

Apply it on our case, for a single column:

    r.db("foodb")
      .table("compounds_foods")
      .indexCreate("match_orig_food_common_name", r.row.match)

If we don't pass an index function, RethinkDB will try to create index for the column that has the same name as requested index name.

Time to use it:

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas', {index:'orig_food_common_name'})
    #=> Executed in 10ms. No results returned.

No result. It's strange that we have no document where its
orig_food_common_name doesn't contain banana. Why so? Well, the simple
index does an exact match, or in other world, it's an equal comparison.
Let's try an exact match:

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas, raw', {index:'orig_food_common_name'})
    #=> Executed in 69ms. 40 rows returned, 40 displayed, more available
    {
    "citation":  "USDA" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 2100 ,
    "created_at": Tue Jan 03 2012 18:33:15 GMT-08:00 ,
    "creator_id": null ,
    "food_id": 208 ,
    "id": 257686 ,
    "orig_citation": null ,
    "orig_compound_id":  "262" ,
    "orig_compound_name":  "Caffeine" ,
    "orig_content":  "0.0" ,
    "orig_food_common_name":  "Bananas, raw" ,
    "orig_food_id":  "09040" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit":  "mg" ,
    "orig_unit_expression": null ,
    "updated_at": Tue Jan 03 2012 18:33:15 GMT-08:00 ,
    "updater_id": null
    }

We can pass multiple keys to `getAll` to have an `or` effect. Meaning RethinkDB
returns document where the index match any of value that we pass.

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas, raw', 'Yoghurt with pear and banana', 'Alfalfa seeds',{index:'orig_food_common_name'})

We can chain to `count` to count how many document we have

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas, raw', 'Yoghurt with pear and banana', 'Alfalfa seeds',{index:'orig_food_common_name'})
      .count()
    #=> 256

Not only used to find document, index can also be used for sorting as well. To sort,
we call `orderBy` and passing index name.

    r.db("foodb").table("compounds_foods")
      .orderBy({index: "orig_food_common_name"})

When passing index, we can wrap it in other expression to change the ordering:

    r.db("foodb").table("compounds_foods")
      .orderBy({index: r.desc("orig_food_common_name")})
      .withFields("orig_food_common_name")
    #=> 
    {
    "orig_food_common_name":  "Zwieback"
    } {
    "orig_food_common_name":  "Zwieback"
    } {
    "orig_food_common_name":  "Zwieback"
    }

Using `withFields`, we can pass a list of field to choose what we want to get
back.

Because index can be used to sort, we can use it to find the value between a
range. In RethinkDB, `between` syntax is:

    table.between(lowerKey, upperKey[, {index: 'id', leftBound: 'closed',
rightBound: 'open'}]) → selection

As you can see, we can only use between on table type. So, take note that
using this, we can find the document between "Apple" and "Banana" range.

    r.db("foodb").table("compounds_foods")
      .between("Apple", "Banana", {index: 'orig_food_common_name'})
      .orderBy({index: r.desc("orig_food_common_name")})
      .withFields("orig_food_common_name")

Without specifying an index, `between` operates on primary index, many RethinkDB 
function has the same behaviour

    r.db("foodb").table("compounds_foods")
      .between(1, 200)
      .count()
    #=> 198

This works when we want to find data based on a single field. How about find
value base on multiple field? Let's meet compound index

## Compound index

Compound index is created by using value of multiple fields. It's very similar to
single index in syntax, just different on how many fields we pass to index
create. Let's take a look at `compounds_foods` table, it contains relationship of
`foods` and `compounds`. We will learn more about JOIN later. For now, let's say
we want to find all `compounds_foods` document where its `compound_id` is 3524
and `food_id` is 287. We are finding on two columns, so we need an index
contains those 2 columns:

    r.db("foodb").table("compounds_foods")
      .indexCreate("compound_food_id", [r.row(row"compound_id"), r.row("food_id")]) 

The only different with simple index is that we have to pass an array of field to
create index. Let's try it:

    r.db("foodb").table("compounds_foods")
      .getAll([354,287], {index: 'compound_food_id'})
    #=>
    RqlRuntimeError: Index `compound_food_id` on table `foodb.compounds_foods` was
    accessed before its construction was finished in:
    r.db("foodb").table("compounds_foods").getAll([354, 287], {index:
    "compound_food_id"})
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We got an error. Looks like the index is not completed created yet. The table
has 

We can query index status:

    r.db("foodb").table("compounds_foods")
      .indexStatus('compound_food_id')
    #=>
    [
    {
    "blocks_processed": 13192 ,
    "blocks_total": 15437 ,
    "function": <binary, 408 bytes, "24 72 65 71 6c 5f..."> ,
    "geo": false ,
    "index":  "compound_food_id" ,
    "multi": false ,
    "outdated": false ,
    "ready": false
    }
    ]

The field ready is false. We can only wait until it finishes. This table is very
big. We can verify:

    r.db("foodb").table("compounds_foods").count()
    #=> 737089

Let's just wait for a bit, make a cup of coffee and come back :). When it's ready,
you should see:

    r.db("foodb").table("compounds_foods")
      .indexStatus('compound_food_id')

    [
    {
    "function": <binary, 408 bytes, "24 72 65 71 6c 5f..."> ,
    "geo": false ,
    "index":  "compound_food_id" ,
    "multi": false ,
    "outdated": false ,
    "ready": true
    }
    ]

Now, try it:
    
    r.db("foodb").table("compounds_foods")
      .getAll([21477,899], {index: 'compound_food_id'})
    #=> Executed in 7ms. 1 row returned
    {
    "citation":  "DFC CODES" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 21477 ,
    "created_at": Tue Sep 11 2012 16:12:30 GMT-07:00 ,
    "creator_id": null ,
    "food_id": 899 ,
    "id": 740574 ,
    "orig_citation": null ,
    "orig_compound_id": null ,
    "orig_compound_name": null ,
    "orig_content": null ,
    "orig_food_common_name":  "Meats" ,
    "orig_food_id":  "WI8000" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit": null ,
    "orig_unit_expression": null ,
    "updated_at": Tue Sep 11 2012 16:12:30 GMT-07:00 ,
    "updater_id": null
    }

With above indexing approach, you found that you have to create a dedicated index
for whatever you want to find. An index contains a single value for a document:
either a single value of field, or an order set of value in case of compound
index. However, life is not that simple. Let's looking at `users` table. It contains
a list of users and their three most favourite foods, stored in field
`favfoods`. That's a single column but it holds many elements. Because of that,
we cannot simply answer the question of who liked `Mushroom`:

let's create an index

    r.db("foodb").table("users").indexCreate('favfoods')

Try to find all users who liked mushrooms.

    r.db("foodb").table("users")
      .getAll('Mushrooms', {index: 'favfoods'})
    #=> Executed in 6ms. No results returned.

Why so? Because since we index the whole field as a single value, we have to match the
whole value of field:

    r.db("foodb").table("users")
      .getAll(["Edible shell" ,
        "Clupeinae (Herring, Sardine, Sprat)" ,
        "Deer" ,
        "Perciformes (Perch-like fishes)" ,
        "Bivalvia (Clam, Mussel, Oyster)"], {index: 'favfoods'})
    #=>
    {
    "favfoods": [
    "Edible shell" ,
    "Clupeinae (Herring, Sardine, Sprat)" ,
    "Deer" ,
    "Perciformes (Perch-like fishes)" ,
    "Bivalvia (Clam, Mussel, Oyster)"
    ] ,
    "id":  "1dd8059c-82ca-4345-9d75-eaa0f8edbf48" ,
    "name":  "Arthur Hegmann"
    }

*Multi index* is used to solve the above question: who likes Banana. A multi index
is used on multiple value, or in other word, an array of value. When RethinkDB
see that we want to use a *multi index*, it tries to loop over all values in the
array of index, and match to each of element of the array.

To create a multi index, all we have to do is to pass the option flag:` multi:
true`


    r.db("foodb").table("users").indexCreate('favfoods_multi', r.row("favfoods"), {multi: true})

Now, let's try it:

    r.db("foodb").table("users")
      .getAll('Mushrooms', {index: 'favfoods_multi'})
    #=>
    {
    "favfoods": [
    "Milk substitute" ,
    "Mushrooms" ,
    "Nuts" ,
    "Hummus" ,
    "Soft-necked garlic"
    ] ,
    "id":  "47110a8f-3c2c-46b8-96d8-244747c1818b" ,
    "name":  "Annabelle Lindgren"
    }

If you notice, we have to pass `r.row(favfoods)` to create an index. Remember
that in order to create an index where its name doesn't match any field, we have to pass
an expression or an anonymous fuction to `indexCreate` to caculate its value.
But we defined `favfoods` index before, so now we cannot create other index with the
same name. We can go back, delete index to clear thing up and save our
namespace:

    r.db("foodb").table("users").indexDrop('favfoods')
    #=> 
    { "dropped": 1 } 
    r.db("foodb").table("users").indexDrop('favfoods_multi')
    #=> 
    { "dropped": 1 } 

Now, let's create a multile index with the same field name:

    r.db("foodb").table("users").indexCreate('favfoods', {multi: true})
    r.db("foodb").table("users").getAll('Mushrooms', {index: 'favfoods'})
    #=>
    {
    "favfoods": [
    "Milk substitute" ,
    "Mushrooms" ,
    "Nuts" ,
    "Hummus" ,
    "Soft-necked garlic"
    ] ,
    "id":  "47110a8f-3c2c-46b8-96d8-244747c1818b" ,
    "name":  "Annabelle Lindgren"
    }

Then another question comes up, can we find all user who like `Mustrooms` and
`Banana`? We may try this:

    r.db("foodb").table("users")
      .getAll('Kiwi', 'Banana', {index: 'favfoods'})

However, that's an `or`. RethinkDB will return documents where its index value
matches either `Kiwi` or `Banana`.

Even more complex, we want to find user who like Kiwi most. Meaning `kiwi` has
to be first element in ther *favfoods* array.

To do that, we see that we are passing business logic into RethinkDB. We have to
somehow represent that logic in RethinkDB, calculate the value, and index the
return value. Let's meet `arbitrary expressions` index. 

## Arbitray expressions index

As its name, the returned value of expression is used to calculate index.

Unfortunately at this moment, we cannot simple answer who like both of banana
and kiwi. We will save it for later chapter when we learn about `map` function.
Now, let's find users
who like kiwi the most. With assumption that the first element of `favfoods` array
is what an user like most.

    r.db("foodb").table("users")
      .indexCreate('most-favourite-food', function (user) {
        return user("favfoods").nth(0)
      })

Given an array, `nth(n)` return n-th element. We call `nth(0)` on array
`favfoods`  that means first
element of array since they are zero-base index.

    r.db("foodb").table("users")
      .getAll('Kiwi', {index: 'most-favourite-food-1'})
    #=>
    {
    "favfoods": [
    "Kiwi" ,
    "Lemon" ,
    "Lime" ,
    "Coffee" ,
    "Sweet orange"
    ] ,
    "id":  "0b83164e-fb42-4273-8db1-ba12be6e580d" ,
    "name":  "Carl Achiban"
    } {
    "favfoods": [
    "Kiwi" ,
    "Banana" ,
    "Peanut" ,
    "Asparagus" ,
    "Common cabbage"
    ] ,
    "id":  "d10b51d7-d321-4b41-bd7d-1367ede0eb30" ,
    "name":  "Luma Ramses"
    }

This index is powerful because we can push more complex searching to database
engine. Let's say we want to find all user who like `Kiwi` most and is a female.

    r.db("foodb").table("users")
      .indexCreate('most-favourite-food-gender', function (user) {
        return [user("gender"), user("favfoods").nth(0)]
      })

Here, we are trying to create non-multi index. The index is an array of gender
and most favorite food item. Now, let's try our index

    r.db("foodb").table("users")
      .getAll(['f', 'Kiwi'], {index: 'most-favourite-food-gender'})
    #=>
    {
    "favfoods": [
    "Kiwi" ,
    "Lemon" ,
    "Lime" ,
    "Coffee" ,
    "Sweet orange"
    ] ,
    "gender":  "f" ,
    "id":  "0b83164e-fb42-4273-8db1-ba12be6e580d" ,
    "name":  "Carl Achiban"
    } {
    "favfoods": [
    "Kiwi" ,
    "Banana" ,
    "Peanut" ,
    "Asparagus" ,
    "Common cabbage"
    ] ,
    "gender":  "f" ,
    "id":  "d10b51d7-d321-4b41-bd7d-1367ede0eb30" ,
    "name":  "Luma Ramses"
    }

One thing I want to remind you is that the return
function in any RethinkDb expression is evaludated on RethinkDB, not on client
language. You cannot just write anything. You have to use RethinkDB expression
in return value so that RethinkDB can calculate it. In previous chapter, we
learn about `expr`, you can use that to turn native object into RethinkDb object
when needed.

Let's look at this example:

    r.table("users").indexCreate("full_name2", function(user) {
        return r.add(user("last_name"), "_", user("first_name"))
    }).run(conn, callback)

We are trying to create an index by appending *last_name* and *first_name*. We
cannot write

    return user("last_name") + user("first_name")

because ReThinkDB won't understand that expression. We have to call `r.add`
function.

However, even if you see something like 

    return user("last_name") + user("first_name")

That doesn't mean RethinkDB understands your native expression. It's actually
your driver overload operator (`+` operator) in this case because your host
language apparently support operator overloading.

If you notice, we don't pass `multi: true` in any of the above examples. Can we use
multi index with arbitray expression index? Yes, we can.

Let's say if we want to find any users who like `Kiwi` or have eaten Kiwi before. We will
create an multi index by concat array `favfoods` and `eatenfoods`


    r.db("foodb").table("users")
      .indexCreate(
        'eateen-or-like-multi', 
        r.add(r.row("eatenfoods"), r.row("favfoods"))
        , {multi: true})

Now, we can use that index:


    r.db("foodb").table("users")
      .getAll('Kiwi', {index:'eateen-or-like-multi'})
    #=>
    {
    "eatenfoods": [
    "Celery leaves" ,
    "Kiwi" ,
    "Rainbow trout" ,
    "Chinese bayberry" ,
    "Hyacinth bean" ,
    "Other sandwich"
    ] ,
    "favfoods": [
    "Honey" ,
    "Cake" ,
    "Butter substitute" ,
    "Cream" ,
    "Sugar"
    ] ,
    "gender":  "m" ,
    "id":  "808cedd5-f2ac-4724-98bc-061ee84755c9" ,
    "name":  "Forrest Jacobs"
    } {
    "eatenfoods": [
    "Jerusalem artichoke" ,
    "Conch" ,
    "Milk and milk products" ,
    "Dumpling" ,
    "Custard apple" ,
    "Sacred lotus" ,
    "Japanese walnut" ,
    "Crab"
    ] ,
    "favfoods": [
    "Kiwi" ,
    "Banana" ,
    "Peanut" ,
    "Asparagus" ,
    "Common cabbage"
    ] ,
    "gender":  "f" ,
    "id":  "d10b51d7-d321-4b41-bd7d-1367ede0eb30" ,
    "name":  "Luma Ramses"
    }
    
How about finding users that liked Kiwi most and have eaten kiwi? We just need to
change the index function, this time we will use anonymous function:

    r.db("foodb").table("users")
      .indexCreate(
        'eatean-or-like-most',
        function (user) {
          return r.add(user("eatenfoods"), [user("favfoods").nth(0)])
        }
        , {multi: true})

Actually, function is just a special case of expression where expression is the
result of function executing. Now, we can try to find:

    r.db("foodb").table("users")
      .getAll('Kiwi', {index: 'eatean-or-like-most'})
    #=>
    {
        "eatenfoods": [
            "Shrimp",
            "Other fish product",
            "Sweet orange",
            "Unclassified food or beverage"
        ],
        "favfoods": [
            "Kiwi",
            "Lemon",
            "Lime",
            "Coffee",
            "Sweet orange"
        ],
        "gender": "f",
        "id": "0b83164e-fb42-4273-8db1-ba12be6e580d",
        "name": "Carl Achiban"
    } {
        "eatenfoods": [
            "Celery leaves",
            "Kiwi",
            "Rainbow trout",
            "Chinese bayberry",
            "Hyacinth bean",
            "Other sandwich"
        ],
        "favfoods": [
            "Honey",
            "Cake",
            "Butter substitute",
            "Cream",
            "Sugar"
        ],
        "gender": "m",
        "id": "808cedd5-f2ac-4724-98bc-061ee84755c9",
        "name": "Forrest Jacobs"
    } {
        "eatenfoods": [
            "Jerusalem artichoke",
            "Conch",
            "Milk and milk products",
            "Dumpling",
            "Custard apple",
            "Sacred lotus",
            "Japanese walnut",
            "Crab"
        ],
        "favfoods": [
            "Kiwi",
            "Banana",
            "Peanut",
            "Asparagus",
            "Common cabbage"
        ],
        "gender": "f",
        "id": "d10b51d7-d321-4b41-bd7d-1367ede0eb30",
        "name": "Luma Ramses"
    }



## Checking index status

As I've said, indexing reduces write performance, therefore it takes time to
create after we issue creating command. Depend on the table size, how many
records we have, we have to wait for an amout of time before using it. We can
check the status of an index to see if it's ready to use

    r.table().indexStatus(indexName)

Such as:

    r.db("foodb").table("compounds_foods").indexStatus("food_id")
    #=> 
    {
    "blocks_processed": 656 ,
    "blocks_total": 11331 ,
    "function": <binary, 181 bytes, "24 72 65 71 6c 5f..."> ,
    "geo": false ,
    "index":  "food_id" ,
    "multi": false ,
    "outdated": false ,
    "ready": false
    }

The `ready` field indicates if the index is ready to use.

Sometimes we just want to say, when the index is ready, please run this:

    r.table.indexWait


## Using index

### Order

Sorting with order without index limit to 100k issue

### Pagination

To pagination data, we will use a combination of `skip`, `limit` and `slice`.

**skip(n)**

: Skip a number of element from the begining of sequence or array

**limit(n)**

: End the sequence after we read up to the give number of limit

**slice

T> ## Where else I can call Skip, Limit, Slice
T>
T> These command can be called on a selection, an array or stream. So you ca

## Transform data

So far, we always taking the value that return from RethinkDB to work with it. In
any real application, you probably want to do some transform around it. If we do
it at application level, for complex thing, it makes sense. But for simple thing,
we might waste another extra loop. Sometime we want to do thing at RethinkDB
level, or we want to use transform data in other ReQL expression.

An example is the function `nth` or `count`. We call them on a sequence, or an
array of data, and they return a different data. They transform original data
into a different piece of data. But `nth` and `count` are simple function. They
don't have any complex logic inside them. Some transform function has complex
logic. With those logic, we have to use some kind of `if ...else...` command, or
loop. To help us with that, RethinkDB has some control structure functions such
as `branch` (similar to `if`) or `forEach`, `do`. RethinkDb shines in these
areas because database engine now seems to have an embedded language in it.

Let's cover more of those functions. Along the way, we will learn somne structure
control command. Now, move on to our next function, **map**.

### Map

Let's say we want to divide our users into 3 groups, who are under 18 years old
are **teenager**, between 18-50 are **adult**, and over 50 years old are
**older**. We have a pattern here, with each document in table, we want to
calculate a new data, depend on their existed data. In RethinkDB, we used
***map*** function.

Map apply a function on document, and return value of function is returned from
query. With our example, in a normal programming language such as Ruby, we can
write:

    users.map do |user|
      if user["age"] <= 18
        "teenager"
      else if user["age"] >18 && user["age"] <50 
        "adult"
      else
        "older"
      end
    end

In RethinkDB, the format of map is:

    sequence1.map([sequence2, ...], mappingFunction) → stream
    array1.map([array2, ...], mappingFunction) → array
    r.map(sequence1[, sequence2, ...], mappingFunction) → stream
    r.map(array1[, array2, ...], mappingFunction) → array

With this example, we have to represent `if` in RethinkDB function. We do that
with `branch`:

    r.branch(test, true_branch, false_branch) → any

Time to write our function:

    r.db("foodb").table("users").map(function (user) {
      return r.branch(
        user("age").lt(18),
        "teenager",
        r.branch(
          user("age").gt(50),
          "older",
          "adult"
        )
      )
    })
    #=>
    "older" "older" "older" "adult" "older" "older" "older" "adult" "older"
    "older" "older" "adult" "teenager" "adult" "adult" "adult" "older" "adult"
    "older" "older" "older" "older" "adult" "teenager" "adult" "older" "older"
    "older" "older" "adult" "adult" "older" "adult" "older" "older" "older" "adult"
    "older" "older" "older"

Yay, we get what we want. But it only returns the value from fuction, we don't
know who is who. Well, that's `map` job. It transforms the whole document into
the return value. How about we return an object, with original `name` field, and
our `group` field, like this:

    r.db("foodb").table("users").map(function (user) {
      return {
        name: user("name"), 
        group: r.branch(
        user("age").lt(18),
        "teenager",
        r.branch(
          user("age").gt(50),
          "older",
          "adult"
        )
        )}
    })
    #=>
    {
    "group":  "adult" ,
    "name":  "Arthur Hegmann"
    } {
    "group":  "older" ,
    "name":  "Ricky Quigley Sr."
    } {
    "group":  "older" ,
    "name":  "Jazmyne Brakus"
    }
    ....


Great. But if we want to return whole document, with extra `group` field, do we
have to repeatedly write every fields? Well, let's meet `merge`.

    r.db("foodb").table("users").map(function (user) {
      return user.merge({
        group: r.branch(
          user("age").lt(18),
          "teenager",
          r.branch(
            user("age").gt(50),
            "older",
            "adult"
          )
        )})
    })

If you wondering whether we can use `row` in `map` expression instead of using function, I would say: Yes, we can. But we cannot do that in the above example because `row` doesn't work in
nested query. In above example, we nested `r.branch` inside `merge`, and inside
other `branch`. 

Let's see an example where we can use `r.row`: couting how many foods they have
eaten:

    r.db("foodb").table("users").map({
      name: r.row("name"),
      total_eaten: r.row("eatenfoods").count()
    })
    #=>
    {
    "name":  "Arthur Hegmann" ,
    "total_eaten": 6
    } {
    "name":  "Ricky Quigley Sr." ,
    "total_eaten": 7
    }

By using `map`, we can pre-calculate some data, either using function or
expression. Let's meet other kind of `mapping` function.

### concatMap

***concatMap*** is very similar to map. It applies function to every element of
sequence. But it's different since it also try to flatten, or concat all
element into a single sequence.

    r.expr([1, 2, 3]).map(function(x) { return [x, x.mul(2)] })
    #=> [[1, 2], [2, 4], [3, 6]]

However, `concatMap` will concat all sub sequence/array into final return data.

    r.expr([1, 2, 3]).concatMap(function(x) { return [x, x.mul(2)] })
    #=> [1, 2, 2, 4, 3, 6]

When is it useful? It looks like very useless, right? Well, let's look at
`favfoods` field. If we want to get a list of `favfoods` on the entire system, we
can do:

    r.db("foodb").table("users").map(
      r.row("favfoods")
    )
    #=>
    [
      "Garden tomato (var.)" ,
      "Linden" ,
      "Lowbush blueberry" ,
      "American cranberry" ,
      "Vanilla"
    ],
    [
      "Swiss chard" ,
      "Chicory roots" ,
      "Grapefruit" ,
      "Jostaberry" ,
      "Spirit"
    ]

As expected, we get an array of array. That's when `concapMap` shines:

    r.db("foodb").table("users").concatMap(
      r.row("favfoods")
    )
    #=>
    Pikeperch
    Pacific ocean perch
    True seal
    Columbidae (Dove, Pigeon)
    Conch
    Kiwi
    Lemon
    Lime
    Coffee
    Sweet orange
    Kiwi
    True seal
    Salmonidae (Salmon, Trout)
    ...

If you notice, we have duplicate data. That's natural because many users may
like the same foods. To get distinct value, you can call `distinct` on the sequence:

    r.db("foodb").table("users").concatMap(
      r.row("favfoods")
    ).distinct()
    #=>
    [
    "Abalone" ,
    "Abiyuch" ,
    "Acerola" ,
    "Acorn" ,
    "Adobo" ,
    "Adzuki bean" ,
    ]

`distinct` accepts an index and use it to differentce document, without any
specified index, it uses primary index, or the `id` value, which is good enough
in our case, because we don't have foods with the same name. Sometimes, you may want
to create extra index for the field and call `distinct` using that index.

Let's dig into a more complex example. For each of foods, let's find all of its
compound.

Let's create an index first:

    r.db("foodb").table("compounds_foods").indexCreate("food_id")

With that index, we can try our query:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return 
          r.db("foodb").table("compounds_foods")
          .getAll(food("id"), {index: "food_id"})
          .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
          .map(function(compound_food) {
            return food.merge({compound: compound_food})
          })
      })
    #=>
    {
    "compound": {
    "compound_id": 21594 ,
    "food_id": 2 ,
    "id": 15609 ,
    "orig_compound_name":  "Fatty acids, total saturated" ,
    "orig_food_common_name":  "Cabbage, savoy, raw"
    } ,
    "id": 2 ,
    "name":  "Savoy cabbage"
    } {
    "compound": {
    "compound_id": 21595 ,
    "food_id": 2 ,
    "id": 15610 ,
    "orig_compound_name":  "Fatty acids, total mono-unsaturated" ,
    "orig_food_common_name":  "Cabbage, savoy, raw"
    } ,
    "id": 2 ,
    "name":  "Savoy cabbage"
    }

Note that we use some `withFields` command to limit on the fields that we want
to include in return document.

Above example won't work with `map`. Because the return value from function
isn't a single value, but another sequence. If you attempt to use `map`, you can
see error clearly:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .map(function (food) {
        return 
          r.db("foodb").table("compounds_foods")
          .getAll(food("id"), {index: "food_id"})
          .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
          .map(function(compound_food) {
            return food.merge({compound: compound_food})
          })
      })
    #=> RqlRuntimeError: Expected type DATUM but found SEQUENCE:

`concatMap` can operator on sequence value from funciton, and try to flatten it
for us. Let's get back to this and break down how it works:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return 
          r.db("foodb").table("compounds_foods")
          .getAll(food("id"), {index: "food_id"})
          .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
          .map(function(compound_food) {
            return food.merge({compound: compound_food})
          })
      })

For every document of foods, it's transformed into a document similar to this:

    [
      {id: id1, name: name1, compound: compound_food_document1}, 
      {id: id1, name: name1, compound: compound_food_document2},
      {id: id1, name: name1, compound: compound_food_documentn},a
    ]

That mean, with a sequence of foods, we will have this(without concatMap):

    [
      {id: id1, name: name1, compound: compound_food_document1}, 
      {id: id1, name: name1, compound: compound_food_document2},
      {id: id1, name: name1, compound: compound_food_documentn},...
    ],
    [
      {id: id2, name: name2, compound: compound_food_document1}, 
      {id: id2, name: name2, compound: compound_food_document2},
      {id: id2, name: name2, compound: compound_food_documentn},...
    ],
    ...

But concat map will fallten array and we have this:

    {id: id1, name: name1, compound: compound_food_document1}, 
    {id: id1, name: name1, compound: compound_food_document2},
    {id: id1, name: name1, compound: compound_food_documentn},...
    ,
    {id: id2, name: name2, compound: compound_food_document1}, 
    {id: id2, name: name2, compound: compound_food_document2},
    {id: id2, name: name2, compound: compound_food_documentn},...
    , ...

That's power of `concatMap`. We can use it to do a join effect. But one problem
remains, as you can see, we have many document with same `food` but different
compound of that food. We can somehow compile them into an array like this:

    {id: id1, name: name1, 
      compound: [compound_food_document1, compound_food_document2, ...]
    },
    {id: id2, name: name2, 
      compound: [compound_food_documentn, compound_food_documentn, ...]
    },...

Let's tweak our `concatMap` a bit.

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return [
          food.merge({compound: 
            r.db("foodb").table("compounds_foods")
            .getAll(food("id"), {index: "food_id"})
            .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
            .limit(10)
          })
        ]
      })

First off, you notice that we wrap food.merge in array. Why so? Because
`concatMap` expects return value from function is a sequence. `map` expects
return value from function is DATUM, likewise. We also call `limit(10)` on the
`compound_foods` sequence to limit first 10 results, sort by primary key, `id`
field of `compound_foods` table in this case.

Instead of creating a map to loop over the `compound_foods` sequence and creating a
document, we simply bring the whole `compound_foods` array to merge into
**food** document. Looks good, run this and here come the error:

    RqlRuntimeError: Expected type DATUM but found SEQUENCE:

Well, merge expect a `DATUM`. A datum is like a single primitive value such as
a number, an array. However, we are passing SEQUENCE. You can understand that we are
expecting an primitive value, but we passed a cursor. Like in Ruby, when we
expect an array, but we pass an enumarator. In RethinkDB, to make this kind of
merge work, we have to explicitly convert it to an array, using `coerceTo` with
parameter **array**.

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return [
          food.merge({compound: 
            r.db("foodb").table("compounds_foods")
            .getAll(food("id"), {index: "food_id"})
            .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
            .limit(10)
            .coerceTo('array')
          })
        ]
      })
    #=>
    {
    "compound": [ ... ] ,
    "id": 2 ,
    "name":  "Savoy cabbage"
    } {
    "compound": [ ... ] ,
    "id": 15 ,
    "name":  "Wild celery"
    }

Now, with `coerceTo` function, we know that we can convert sequence into
`array`. So can we achieve this with map, instead of `concatMap`. Yes, and it's even more
simpler:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .map(function (food) {
        return
          food.merge({compound: 
            r.db("foodb").table("compounds_foods")
            .getAll(food("id"), {index: "food_id"})
            .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
            .limit(10)
            .coerceTo('array')
          })
      })

We no longer have to wrap it in `[]` because `map` can work with OBJECT. With
this example, we see that `concatMap` and `map` sometime can be used
interchangably depend on how we want to model the data.

## Index and Map

I promised you an answer to quesiton who like both of Kiwi and banana. As you
can guess, we have to create a multi index with each of value is a pair of
favourite foods. It's very hard to do this without `map`. We are thinking of
two nested loops. With map, we can do this:


    r.db("foodb")
      .table("users")
      .indexCreate("food-test-idx-1", function (food) {
        return
          food("favfoods")
            .concatMap(function (favfood) {
              return
                food("favfoods").map(function (favfood2) {
                  return [favfood, favfood2]
                  })
            })
      }, {multi: true})

We will do a map. With each of element of `favfoods, we try to create a new
array of two elements by combining the element with each of element of `favfoods`
itself. We use `concatMap` to flatten array, and set `multi: true` because this
is a multi indexer: we are returning an array from index function.

And now, we can use that index, pass a pair of value:

    r.db("foodb")
      .table("users")
      .getAll(['Spirit', 'Grapefruit'], {index: "food-test-idx-1"})
    #=>
    {
    "age": 41 ,
    "eatenfoods": [
    "Hummus" ,
    "Common beet"
    ] ,
    "favfoods": [
    "Swiss chard" ,
    "Chicory roots" ,
    "Grapefruit" ,
    "Jostaberry" ,
    "Spirit"
    ] ,
    "gender":  "f" ,
    "id":  "3700fa48-2806-4cb2-9bfb-a5d90d6cfd38" ,
    "name":  "Wilburn Price"
    }

The order isn't important here, because we create the pair of array on every
element if itself. Such as with [a,b,c] array, we will have this array via map:

  [a,a], [a,b], [a,c], [b,a], [b,b], [b,c], [c, a], [c, b], [c, a]

We can elimiate [a,a], [b,b], [c,c] because they are useless. We just need to
put them in `branch` command:

    r.db("foodb")
      .table("users")
      .indexCreate("food-test-idx-2", function (food) {
        return food("favfoods").concatMap(function (favfood) {
          return food("favfoods").map(function (favfood22)    {
            return r.branch(favfood.eq(favfood2),
                [],
                [favfood, favfood2]
                )
          })
        })
      }, {multi: true})

With each element, if we see the value of two elements are the same, we return an
empty array, otherwise, we return combination array of them.

This runs fast but it has its own limitation. We cannot create more than 256
index on multi index. Other approach, not as fast, but scale better is to use
double `filter`. First we `getAll` using an index, the `filter` it


# Wrap up

This chapter is quite long. So far we've learned about index. We know how to create:

  * Simple index
  * Compound index
  * Multi value index
  * Arbitrary expression index

We've also learned how to leverage index to sort, filter data. Two important
transform functions you also learn:

  * map:
  * concatMap: 

And finally, by leveraging `map`, you can easily create multi index.
